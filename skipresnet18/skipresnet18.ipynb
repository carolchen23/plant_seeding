{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class PreInputBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, outchannel, stride=1):\n",
    "        super(PreInputBlock, self).__init__()\n",
    "        self.pre = nn.ModuleList([\n",
    "         nn.Sequential(nn.Conv2d(3, outchannel, 1, stride, bias=False), nn.BatchNorm2d(outchannel))])\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for model in self.pre:\n",
    "            out = model(out)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "class skipresnet18_2(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=12):\n",
    "        super(skipresnet18_2, self).__init__()\n",
    "        self.k = 1\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.mish = nn.Mish()\n",
    "\n",
    "        \n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(64),nn.ReLU(inplace=True))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(64))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(64),nn.ReLU(inplace=True))\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(64))\n",
    "        \n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False), nn.BatchNorm2d(128),nn.ReLU(inplace=True))\n",
    "        self.layer6 = nn.Sequential(nn.Conv2d(128, 128, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(128))\n",
    "        self.layer7 = nn.Sequential(nn.Conv2d(128, 128, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(128),nn.ReLU(inplace=True))\n",
    "        self.layer8 = nn.Sequential(nn.Conv2d(128, 128, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(128))\n",
    "        \n",
    "\n",
    "        self.layer9 = nn.Sequential(nn.Conv2d(128, 256, 3, stride=2, padding=1, bias=False), nn.BatchNorm2d(256),nn.ReLU(inplace=True))\n",
    "        self.layer10 = nn.Sequential(nn.Conv2d(256, 256, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(256))\n",
    "        self.layer11 = nn.Sequential(nn.Conv2d(256, 256, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(256),nn.ReLU(inplace=True))\n",
    "        self.layer12 = nn.Sequential(nn.Conv2d(256, 256, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(256))\n",
    "\n",
    "        self.layer13 = nn.Sequential(nn.Conv2d(256, 512, 3, stride=2, padding=1, bias=False), nn.BatchNorm2d(512),nn.ReLU(inplace=True))\n",
    "        self.layer14 = nn.Sequential(nn.Conv2d(512, 512, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(512))\n",
    "        self.layer15 = nn.Sequential(nn.Conv2d(512, 512, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(512),nn.ReLU(inplace=True))\n",
    "        self.layer16 = nn.Sequential(nn.Conv2d(512, 512, 3, stride=1, padding=1, bias=False), nn.BatchNorm2d(512))\n",
    "\n",
    "        self.downsample1 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False), nn.BatchNorm2d(128))\n",
    "        self.downsample2 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False), nn.BatchNorm2d(256))\n",
    "        self.downsample3 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False), nn.BatchNorm2d(512))\n",
    "\n",
    "        self.pre1 = nn.Sequential(nn.Conv2d(3, 64, 1, stride=4, bias=False), nn.BatchNorm2d(64))\n",
    "        self.pre2 = nn.Sequential(nn.Conv2d(3, 64, 1, stride=4, bias=False), nn.BatchNorm2d(64))\n",
    "        \n",
    "        self.pre3 = nn.Sequential(nn.Conv2d(3, 128, 1, stride=8, bias=False), nn.BatchNorm2d(128))      \n",
    "        self.pre4 = nn.Sequential(nn.Conv2d(3, 128, 1, stride=8, bias=False), nn.BatchNorm2d(128))\n",
    "\n",
    "        self.pre5 = nn.Sequential(nn.Conv2d(3, 256, 1, stride=16, bias=False), nn.BatchNorm2d(256))   \n",
    "        self.pre6 = nn.Sequential(nn.Conv2d(3, 256, 1, stride=16, bias=False), nn.BatchNorm2d(256))\n",
    "\n",
    "        self.pre7 = nn.Sequential(nn.Conv2d(3, 512, 1, stride=32, bias=False), nn.BatchNorm2d(512))  \n",
    "        self.pre8 = nn.Sequential(nn.Conv2d(3, 512, 1, stride=32, bias=False), nn.BatchNorm2d(512))\n",
    "\n",
    "        self.avg = nn.AvgPool2d(4, stride=1)\n",
    "\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x0):\n",
    "        x1 = self.conv1(x0)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        x1 = self.maxpool(x1)\n",
    "            \n",
    "        x2 = self.layer1(x1)\n",
    "        x3 = self.layer2(x2)\n",
    "        if self.k == 2:\n",
    "            pre_x1 = self.pre1(x0)\n",
    "            x3 = pre_x1 + x3 \n",
    "        else:\n",
    "            x3 = x1 + x3\n",
    "        x3 = self.relu(x3)\n",
    "            \n",
    "        x4 = self.layer3(x3)\n",
    "        x5 = self.layer4(x4)\n",
    "        if self.k == 3:\n",
    "            pre_x2 = self.pre2(x0)\n",
    "            x5 = pre_x2 + x5\n",
    "        else:\n",
    "            x5 = x3 + x5\n",
    "        x5 = self.relu(x5)\n",
    "            \n",
    "        x50 = self.downsample1(x5)\n",
    "        x6 = self.layer5(x5)\n",
    "        x7 = self.layer6(x6)\n",
    "        if self.k == 4:\n",
    "            pre_x3 = self.pre3(x0)\n",
    "            x7 = pre_x3 + x7 \n",
    "        else:\n",
    "            x7 = x50 + x7\n",
    "        x7 = self.relu(x7)\n",
    "            \n",
    "        x8 = self.layer7(x7)\n",
    "        x9 = self.layer8(x8)\n",
    "        if self.k == 5:\n",
    "            pre_x4 = self.pre4(x0)\n",
    "            x9 = pre_x4 + x9 \n",
    "        else:\n",
    "            x9 = x7 + x9\n",
    "        x9 = self.relu(x9)\n",
    "            \n",
    "        x90 = self.downsample2(x9)\n",
    "        x10 = self.layer9(x9)\n",
    "        x11 = self.layer10(x10)\n",
    "        if self.k == 6:\n",
    "            pre_x5 = self.pre5(x0)\n",
    "            x11 = pre_x5 + x11 \n",
    "        else:\n",
    "            x11 = x90 + x11\n",
    "        x11 = self.relu(x11)\n",
    "            \n",
    "        x12 = self.layer11(x11)\n",
    "        x13 = self.layer12(x12)\n",
    "        if self.k == 7:\n",
    "            pre_x6 = self.pre6(x0)\n",
    "            x13 = pre_x6 + x13 \n",
    "        else:\n",
    "            x13 = x11 + x13\n",
    "        x13 = self.relu(x13)\n",
    "            \n",
    "        x130 = self.downsample3(x13)\n",
    "        x14 = self.layer13(x13)\n",
    "        x15 = self.layer14(x14)\n",
    "        if self.k == 8:\n",
    "            pre_x7 = self.pre7(x0)\n",
    "            x15 = pre_x7 + x15\n",
    "        else:\n",
    "            x15 = x130 + x15\n",
    "        x15 = self.relu(x15)\n",
    "            \n",
    "        x16 = self.layer15(x15)\n",
    "        x17 = self.layer16(x16)\n",
    "        if self.k == 9:\n",
    "            pre_x8 = self.pre8(x0)\n",
    "            x17 = pre_x8 + x17 \n",
    "        else:\n",
    "            x17 = x15 + x17\n",
    "        x17 = self.relu(x17)\n",
    "\n",
    "        out = self.avg(x17)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        return out \n",
    "\n",
    "\n",
    "    def GetK(self, k):\n",
    "        self.k = k\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from numpy import log2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import flatten\n",
    "from torch.nn.modules.flatten import Flatten\n",
    "from torch.nn.modules.pooling import MaxPool2d\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, dataloader, Subset\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import KFold\n",
    "#import torch.optim.lr_scheduler as lr_scheduler\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "\n",
    "\n",
    "# 图像预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(size=(128,128)),\n",
    "    transforms.RandomHorizontalFlip(),  # 图像一半的概率翻转，一半的概率不翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),  # R,G,B每层的归一化用到的均值和方差\n",
    "])\n",
    "\n",
    "transform_valid = transforms.Compose([\n",
    "    transforms.Resize(size=(128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "\n",
    "# 训练数据集\n",
    "train_dataset = ImageFolder(root='../input/newdata3/train/', transform=transform_train)  \n",
    "\n",
    "\n",
    "num_train = int(len(train_dataset))\n",
    "\n",
    "\n",
    "# 定义K-fold对象\n",
    "Kf_train = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# 添加tensorboard画图可视化\n",
    "writer = SummaryWriter(\"../skipresnet18/logs_train_kfold\")\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "model = skipresnet18_2().to(device)\n",
    "\n",
    "\n",
    "#创建损失函数（交叉熵损失函数）\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn.to(device)\n",
    "#创建优化器\n",
    "LR = 0.001#或者使用1e-2代替0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "# 获取网络参数\n",
    "def GetParametaer(net):\n",
    "    # Get parameters of the net\n",
    "    list = []\n",
    "    for __, parameter in net.named_parameters():\n",
    "        list.append(parameter)\n",
    "    \n",
    "    return list\n",
    "  \n",
    "def GetNum(NumOfLayers,x):\n",
    "\n",
    "    model.GetK(NumOfLayers)\n",
    "    x = model(x)\n",
    "    return x\n",
    "#bitch_size    \n",
    "# 从不同路径进入后可以得到每一层的输出\n",
    "def Get_layers_OutNums(x):\n",
    "    list_3 = []\n",
    "    for i in range(1,10):\n",
    "        temp = x\n",
    "        temp = GetNum(i,temp)\n",
    "        temp = F.softmax(temp,dim=1)\n",
    "        list_3.append(temp)\n",
    "    return list_3\n",
    "\n",
    "\n",
    "\n",
    "# 获得损失值最小的那条路径\n",
    "def LossOfEveryLayers(x, y,LossFunc):\n",
    "    #Get the loss ofc every linaer layer\n",
    "    loss_of_layer = []\n",
    "    for i in range(9):\n",
    "        # LossFunc：交叉熵，x是图片的预测输出，y是标签值\n",
    "        loss_of_layer.append(LossFunc(x[i],y))\n",
    "\n",
    "\n",
    "    return loss_of_layer.index(min(loss_of_layer))+1\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def OutPut(layers_out):\n",
    "    layers_out_ = torch.stack(layers_out,0).to(device)\n",
    "\n",
    "    temp2 = torch.max(layers_out_,2)[0].argmax(0)\n",
    "\n",
    "    temp3 = torch.arange(0,len(temp2))\n",
    "    \n",
    "    output_  = layers_out_[temp2,temp3].to(device)\n",
    "    \n",
    "    return output_\n",
    "\n",
    "def returnk(layers_out):\n",
    "   \n",
    "    layers_out_ = torch.stack(layers_out,0).to(device)\n",
    "    temp = torch.max(layers_out_,2)[0].argmax(0)\n",
    "    temp2 = temp.tolist()\n",
    "    k = max(temp2,key=temp2.count)+1\n",
    "    return k\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#训练的次数\n",
    "total_train_step = 0\n",
    "#测试次数\n",
    "total_test_step = 0\n",
    "total_train_accuracy = 0\n",
    "# Decey_x = 0.5\n",
    "total_train_accuracy_list = []\n",
    "total_train_loss_list = []\n",
    "total_test_accuracy_list = []\n",
    "total_test_loss_list = []\n",
    "val_accuracies = []\n",
    "change_k = 0\n",
    "best_acc = 0\n",
    "#print(\"加载模型...\")\n",
    "#with open(\"../\",'rb') as f:\n",
    "#    model.load_state_dict(torch.load(f))\n",
    "#print(\"加载完毕!\")\n",
    "\n",
    "for train_index, val_index in Kf_train.split(range(num_train)):\n",
    "    train_kfold_subset = Subset(train_dataset, train_index)\n",
    "    val_kfold_subset =Subset(train_dataset, val_index)\n",
    "\n",
    "    trainloader = DataLoader(train_kfold_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    validloader = DataLoader(val_kfold_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "   \n",
    "    for i in range(0, 30):\n",
    "    \n",
    "        print(\"第{}轮训练开始\".format(i+1))\n",
    "        total_train_loss = 0\n",
    "        total_accuracy1 = 0\n",
    "        total_accuracy2 = 0\n",
    "        total_accuracy3 = 0\n",
    "\n",
    "        model.train()\n",
    "        for data in tqdm(trainloader):\n",
    "\n",
    "            imgs, labels = data\n",
    "            imgs = imgs.to(device)\n",
    "            imgs = imgs.view(-1,3,128,128)                               \n",
    "            labels = labels.to(device)\n",
    "\n",
    "        \n",
    "            if i<change_k:\n",
    "                k = 1\n",
    "                optimizer.zero_grad()\n",
    "                model.GetK(k)\n",
    "                output = model(imgs)\n",
    "                loss = loss_fn(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            #scheduler.step(loss)\n",
    "                total_train_loss += loss.item()\n",
    "                total_train_step = total_train_step + 1\n",
    "                accuracy1 = (output.argmax(1)==labels).sum()\n",
    "                total_accuracy1 += accuracy1\n",
    "            \n",
    "            else:\n",
    "                layers_out = Get_layers_OutNums(imgs)\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "      \n",
    "            # 1.最小损失值路径选择算法\n",
    "                k_1 = LossOfEveryLayers(layers_out,labels,loss_fn)\n",
    "    #         print(\"训练\",k_1)\n",
    "            # 选择损失值最小的输入路径\n",
    "                model.GetK(k_1)\n",
    "    #         print(test_net.k)\n",
    "                outputs1 = model(imgs)\n",
    "                loss1 = loss_fn(outputs1,labels)\n",
    "\n",
    "\n",
    "           # 3.最优路径统计算法 \n",
    "                k3 = returnk(layers_out) \n",
    "    #         print(\"训练\",k3)\n",
    "                model.GetK(k3)\n",
    "                outputs3 = model(imgs)\n",
    "    #         print(test_net.k)\n",
    "                loss3 = loss_fn(outputs3,labels)                                                                                                                                                                                                                                      \n",
    "    #         loss = loss3\n",
    "\n",
    "             #2.个体最优路径选择算法\n",
    "                outputs2 = OutPut(layers_out)\n",
    "                loss2 = loss_fn(outputs2,labels)\n",
    "            \n",
    "                loss = loss1+loss2+loss3\n",
    "    #         loss = loss2+loss3\n",
    "\n",
    "            \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            #scheduler.step(loss)\n",
    "\n",
    "                total_train_loss += loss.item()\n",
    "                total_train_step = total_train_step + 1\n",
    "    \n",
    "    #             print(\"训练次数:{}，loss3: {}\".format(total_train_step,loss3.item()))\n",
    "    #             print(\"训练次数:{}，loss2: {}，loss3: {}\".format(total_train_step,loss2.item(),loss3.item()))\n",
    "    #             print(\"训练次数:{}，loss1: {}，loss2: {}\".format(total_train_step,loss1.item(),loss2.item()))\n",
    "    \n",
    "                accuracy1 = (outputs1.argmax(1)==labels).sum()\n",
    "                accuracy2 = (outputs2.argmax(1)==labels).sum()\n",
    "                accuracy3 = (outputs3.argmax(1)==labels).sum()\n",
    "                total_accuracy1 += accuracy1\n",
    "                total_accuracy2 += accuracy2\n",
    "                total_accuracy3 += accuracy3\n",
    "        #print(\"训练次数:{}，loss1: {}，loss2: {}，loss3: {}\".format(total_train_step,loss1.item(),loss2.item(),loss3.item()))\n",
    "        if i<change_k:\n",
    "            train_accurary1 = total_accuracy1/len(train_index)\n",
    "            print(total_train_loss)\n",
    "            print(\"66666在训练集上的正确率：{}\".format(train_accurary1))\n",
    "        else: \n",
    "            train_accurary1 = total_accuracy1/len(train_index) \n",
    "            train_accurary2 = total_accuracy2/len(train_index)\n",
    "            train_accurary3 = total_accuracy3/len(train_index)       \n",
    "            #print(\"在训练集上的loss：{}\".format(total_train_loss))\n",
    "            #print(\"在训练集上的正确率：{}\".format(train_accurary1))\n",
    "            #print(\"在训练集上的正确率（不用k）：{}\".format(train_accurary2))\n",
    "            print(\"在训练集上的正确率（使用计数k）：{}\".format(train_accurary3))\n",
    "        total_train_accuracy_list.append(train_accurary1)\n",
    "        total_train_loss_list.append(total_train_loss)\n",
    "\n",
    "        print(\"开始测试。。。\")\n",
    "        total_accuracy = 0\n",
    "    #测试步骤\n",
    "    #test_net.eval()\n",
    "        total_test_loss = 0\n",
    "        total_test_step = 0\n",
    "\n",
    "    #model.eval()\n",
    "        with torch.no_grad():\n",
    "        #test_net.eval()\n",
    "            for data in tqdm(validloader):\n",
    "            #test_net.eval()\n",
    "                imgs, labels = data\n",
    "                imgs = imgs.to(device)\n",
    "            #imgs = imgs.view(-1,1,28,28)                              \n",
    "                imgs = imgs.view(-1,3,128,128)\n",
    "\n",
    "                labels = labels.to(device)\n",
    "                if i<change_k:\n",
    "                    k=1\n",
    "                    model.GetK(k)\n",
    "                    output_s = model(imgs)\n",
    "                else:\n",
    "                    layers_out2 = Get_layers_OutNums(imgs)\n",
    "            \n",
    "                    k = returnk(layers_out2)\n",
    "                    model.GetK(k)\n",
    "                    output_s = model(imgs)\n",
    "\n",
    "                loss = loss_fn(output_s,labels)\n",
    "                total_test_loss = total_test_loss + loss.item()\n",
    "                total_test_step = total_test_step + 1\n",
    "            #if total_test_step%40 == 0:\n",
    "            #   print(\"训练次数{}，loss{}\".format(total_test_step,loss.item()))\n",
    "                accuracy = (output_s.argmax(1)==labels).sum()\n",
    "                total_accuracy += accuracy \n",
    "            test_accurary = total_accuracy/len(val_index)\n",
    "            print(\"在测试集上的正确率：{}\".format(test_accurary))\n",
    "            #print(\"在测试集上的loss：{}\".format(total_test_loss)) \n",
    "        # 将每次测试结果实时写入acc.txt文件中\n",
    "            print('Saving model......')\n",
    "            torch.save(model.state_dict(), f'../skipresnet18/epoch_kfold/skipresnet18_10{i + 1}.pth')\n",
    "            writer.add_scalar(\"test_loss\", total_test_loss, total_test_step) \n",
    "            total_test_accuracy_list.append(test_accurary)\n",
    "            total_test_loss_list.append(total_test_loss)\n",
    "#     time_end=time.time()\n",
    "#     print('totally cost',time_end-time_start)\n",
    "            if test_accurary > best_acc:\n",
    "                f3 = open(\"../skipresnet18/acc(5fold).txt\", \"w\")\n",
    "                f3.write(f\"训练轮次为{i + 1}时,准确率最高!准确率为{test_accurary}\")\n",
    "                f3.close()\n",
    "                best_acc = test_accurary\n",
    "\n",
    "        val_accuracies.append(best_acc)\n",
    "    print(\"训练结束。。。\")\n",
    "\n",
    "average_val_accuracy = sum(val_accuracies) / len(val_accuracies)\n",
    "\n",
    "print(f\"Average Validation Accuracy: {average_val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(total_test_accuracy_list)):\n",
    "    with open('../skipresnet18/skipresnet18_acc(5fold).txt', 'a') as f:\n",
    "        f.write('%d %.5f %.5f %.5f %.5f\\n' % (i+1,total_train_accuracy_list[i],total_train_loss_list[i],total_test_accuracy_list[i],total_test_loss_list[i]))\n",
    "#     with open('skip18_train_accura/te_records_k.txt', 'a') as f:\n",
    "#         f.write('%d %.3f\\n' % (i+1,total_train_accuracy_list[i]))\n",
    "torch.save(model.state_dict(),\"../skipresnet18/skipresnet18(5kfold).pkl\")\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Validation Accuracy: {average_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from numpy import log2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules import flatten\n",
    "from torch.nn.modules.flatten import Flatten\n",
    "from torch.nn.modules.pooling import MaxPool2d\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, dataloader\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import roc_curve, auc, f1_score,precision_recall_curve,average_precision_score\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(size=(128,128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 测试训练集\n",
    "testset = ImageFolder(root='../input/newdata3/test/', transform=transform_test )\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "seed_n = 121\n",
    "print('seed is ' + str(seed_n))\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed_n)\n",
    "random.seed(seed_n)\n",
    "np.random.seed(seed_n)\n",
    "torch.manual_seed(seed_n)\n",
    "torch.cuda.manual_seed(seed_n)\n",
    "torch.cuda.manual_seed_all(seed_n)\n",
    "            # torch.backends.cudnn.deterministic=True\n",
    "            # torch.backends.cudnn.benchmark = False\n",
    "            # torch.backends.cudnn.enabled = False\n",
    "            # torch.use_deterministic_algorithms(True)\n",
    "            # os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_n)  # 为了禁止hash随机化，使得实验可复现。\n",
    "\n",
    "\n",
    "#数据集长度\n",
    "test_data_size = len(testset)\n",
    "print(\"测试集长度：{}\".format(test_data_size))\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "test_net = skipresnet18_2()\n",
    "\n",
    "test_net.load_state_dict(torch.load(\"../skipresnet18/skipresnet18(5kfold).pkl\"))\n",
    "\n",
    "\n",
    "test_net.to(device)\n",
    "#创建损失函数\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "loss_fn.to(device)\n",
    "#创建优化器\n",
    "learning_rata = 0.001\n",
    "#learning_rata = 0.01#或者使用1e-2代替0.01\n",
    "optimizer = torch.optim.SGD(test_net.parameters(),lr=learning_rata,momentum=0.9, weight_decay=5e-4)\n",
    "num_classes = 12\n",
    "# 存储预测得分\n",
    "score_list = []\n",
    "# 存储真实标签\n",
    "label_list = []\n",
    "\n",
    "\n",
    "def GetParametaer(net):\n",
    "    # Get parameters of the net\n",
    "    list = []\n",
    "    for __, parameter in net.named_parameters():\n",
    "        list.append(parameter)\n",
    "    \n",
    "    return list\n",
    "  \n",
    "def GetNum(NumOfLayers,x):\n",
    "\n",
    "    test_net.GetK(NumOfLayers)\n",
    "    x = test_net(x)\n",
    "    return x\n",
    "#bitch_size    \n",
    "#可以得到每一层的输出\n",
    "def Get_layers_OutNums(x):\n",
    "    list_3 = []\n",
    "    for i in range(1,10):\n",
    "        temp = x\n",
    "        temp = GetNum(i,temp)\n",
    "        temp = F.softmax(temp,dim=1)\n",
    "        list_3.append(temp)\n",
    "    return list_3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LossOfEveryLayers(x, y,LossFunc):\n",
    "    #Get the loss ofc every linaer layer\n",
    "    loss_of_layer = []\n",
    "    for i in range(9):\n",
    "        loss_of_layer.append(LossFunc(x[i],y))\n",
    "\n",
    "\n",
    "    return loss_of_layer.index(min(loss_of_layer))+1\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def OutPut(layers_out):\n",
    "    layers_out_ = torch.stack(layers_out,0).to(device)\n",
    "\n",
    "    temp2 = torch.max(layers_out_,2)[0].argmax(0)\n",
    "\n",
    "    temp3 = torch.arange(0,len(temp2))\n",
    "    \n",
    "    output_  = layers_out_[temp2,temp3].to(device)\n",
    "    \n",
    "    return output_\n",
    "\n",
    "def returnk(layers_out):\n",
    "    layers_out_ = torch.stack(layers_out,0).to(device)\n",
    "    temp = torch.max(layers_out_,2)[0].argmax(0)\n",
    "    temp2 = temp.tolist()\n",
    "    k = max(temp2,key=temp2.count)+1\n",
    "    return k\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "#训练的次数\n",
    "total_train_step = 0\n",
    "#测试次数\n",
    "total_test_step = 0\n",
    "total_train_accuracy = 0\n",
    "# Decey_x = 0.5\n",
    "total_train_accuracy_list = []\n",
    "total_test_accuracy_list = []\n",
    "change_k = 0\n",
    "\n",
    "\n",
    "total_accuracy = 0\n",
    "    #测试步骤\n",
    "    # test_net.eval()\n",
    "total_test_loss = 0\n",
    "total_test_step = 0\n",
    "# 测试模型\n",
    "correct = [0] * 12\n",
    "total = [0] * 12\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(testloader):\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        # images = images.view(-1,3,32,32)\n",
    "        labels = labels.to(device)\n",
    "        layers_out2 = Get_layers_OutNums(images)\n",
    "            \n",
    "        k = returnk(layers_out2)\n",
    "        test_net.GetK(k)\n",
    "        outputs = test_net(images)\n",
    "        score_temp = outputs\n",
    "        score_list.extend(score_temp.detach().cpu().numpy())\n",
    "        label_list.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.extend(predicted.tolist())\n",
    "        y_true.extend(labels.tolist())\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            total[label] += 1\n",
    "            if predicted[i] == label:\n",
    "                correct[label] += 1\n",
    "    score_array = np.array(score_list)\n",
    "    # 将label转换为onehot形式\n",
    "    label_tensor = torch.tensor(label_list)\n",
    "    label_tensor = label_tensor.reshape((label_tensor.shape[0],1))\n",
    "    label_onehot = torch.zeros(label_tensor.shape[0], num_classes)\n",
    "    label_onehot.scatter_(dim=1, index=label_tensor, value=1)\n",
    "    label_onehot = np.array(label_onehot)\n",
    "    print(\"score_array:\", score_array.shape)\n",
    "    print(\"label_onehot:\", label_onehot.shape)\n",
    "\n",
    "    #调用sklearn库，计算每个类别对应的precision和recall\n",
    "    precision_dict = dict()\n",
    "    recall_dict = dict()\n",
    "    average_precision_dict = dict()\n",
    "    for i in range(num_classes):\n",
    "        precision_dict[i], recall_dict[i], _ = precision_recall_curve(label_onehot[:, i], score_array[:, i])\n",
    "        average_precision_dict[i] = average_precision_score(label_onehot[:, i], score_array[:, i])\n",
    "        print(precision_dict[i].shape, recall_dict[i].shape, average_precision_dict[i])\n",
    "\n",
    "    # micro\n",
    "    precision_dict[\"micro\"], recall_dict[\"micro\"], _ = precision_recall_curve(label_onehot.ravel(),\n",
    "                                                                              score_array.ravel())\n",
    "    average_precision_dict[\"micro\"] = average_precision_score(label_onehot, score_array, average=\"micro\")\n",
    "    print('Average precision score, micro-averaged over all classes: {0:0.4f}'.format(average_precision_dict[\"micro\"]))\n",
    " \n",
    "    # 绘制所有类别平均的pr曲线\n",
    "    plt.figure()\n",
    "    plt.step(recall_dict['micro'], precision_dict['micro'], where='post')\n",
    " \n",
    "    plt.xlabel('Recall',fontsize='xx-large')\n",
    "    plt.ylabel('Precision',fontsize='xx-large')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(\n",
    "        'AP={0:0.4f}'\n",
    "        .format(average_precision_dict[\"micro\"]),fontsize='xx-large')\n",
    "    plt.savefig(\"../skipresnet18/set12_pr_curve1.jpg\")\n",
    "\n",
    "# 输出每个类别的准确率\n",
    "for i in range(12):\n",
    "    print('Accuracy of %5s : %.3f %%' % (\n",
    "        testset.classes[i], 100 * correct[i] / total[i]))\n",
    "\n",
    "\n",
    "# 将预测结果转换为标签\n",
    "y_pred_labels = np.array(y_pred)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_true, y_pred_labels)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "# 添加数值\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        plt.annotate(str(cm[i][j]), xy=(j, i), horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(12)\n",
    "plt.xticks(tick_marks, ['1', '2', '3', '4','5','6', '7', '8', '9','10', '11','12'], rotation=45)\n",
    "plt.yticks(tick_marks, ['1', '2', '3', '4','5','6', '7', '8', '9','10', '11','12'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "# plt.show()\n",
    "plt.savefig('../skipresnet18/confusion_matrixA_5kfold1.png')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 计算准确率、召回率、精确率和 F1 值\n",
    "target_names = ['1', '2', '3', '4','5','6', '7', '8', '9','10', '11','12']\n",
    "print(classification_report(y_true, y_pred_labels, target_names=target_names,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
